# 스크립트 기반 이미지-영상 생성 완전 가이드

## 📋 목차
1. [개요](#개요)
2. [이미지 생성 AI 툴](#이미지-생성-ai-툴)
3. [영상 생성 AI 툴](#영상-생성-ai-툴)
4. [파이썬 코드 구현](#파이썬-코드-구현)
5. [실전 워크플로우](#실전-워크플로우)
6. [고급 기법](#고급-기법)
7. [비용 최적화 전략](#비용-최적화-전략)

---

## 개요

기획한 스크립트에 맞춰서 이미지와 영상을 자동으로 생성하는 방법들을 정리한 완전 가이드입니다. AI 툴과 파이썬 코드를 활용하여 콘텐츠 제작을 자동화할 수 있습니다.

---

## 이미지 생성 AI 툴

### 🎨 상용 AI 이미지 생성 도구

#### 1. DALL-E 3 (OpenAI)
- **특징**: 고품질 이미지 생성, 텍스트 프롬프트 기반
- **장점**: 정확한 텍스트 해석, 일관성 있는 스타일
- **단점**: 비용이 높음, API 제한
- **가격**: $0.040/이미지 (1024x1024)

#### 2. Midjourney
- **특징**: 아트스타일 이미지 생성에 특화
- **장점**: 예술적 품질, 다양한 스타일 옵션
- **단점**: Discord 기반, 실시간 생성
- **가격**: $10-60/월

#### 3. Stable Diffusion
- **특징**: 오픈소스, 로컬 실행 가능
- **장점**: 무료, 커스터마이징 가능
- **단점**: 하드웨어 요구사항 높음
- **가격**: 무료 (로컬 실행)

#### 4. Adobe Firefly
- **특징**: 상업적 사용 가능한 이미지 생성
- **장점**: 저작권 문제 없음, Adobe 생태계 통합
- **단점**: 제한적인 스타일 옵션
- **가격**: $22.99/월 (Creative Cloud)

### 🔧 파이썬 코드로 이미지 생성

#### Stable Diffusion 파이썬 구현
```python
# 필요한 라이브러리 설치
# pip install diffusers transformers torch

from diffusers import StableDiffusionPipeline
import torch
from PIL import Image
import os

class ImageGenerator:
    def __init__(self, model_name="runwayml/stable-diffusion-v1-5"):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.pipe = StableDiffusionPipeline.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        )
        self.pipe = self.pipe.to(self.device)
    
    def generate_image(self, prompt, negative_prompt="", width=512, height=512, num_images=1):
        """이미지 생성"""
        images = self.pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_images_per_prompt=num_images,
            num_inference_steps=50
        ).images
        
        return images
    
    def generate_scene_images(self, script_scenes):
        """스크립트 장면별 이미지 생성"""
        generated_images = []
        
        for i, scene in enumerate(script_scenes):
            print(f"장면 {i+1} 생성 중: {scene['description']}")
            
            images = self.generate_image(
                prompt=scene['description'],
                negative_prompt=scene.get('negative_prompt', ''),
                width=scene.get('width', 512),
                height=scene.get('height', 512)
            )
            
            # 이미지 저장
            for j, img in enumerate(images):
                filename = f"scene_{i+1:03d}_{j+1}.png"
                img.save(f"output/images/{filename}")
                generated_images.append({
                    'scene_id': i+1,
                    'filename': filename,
                    'description': scene['description']
                })
        
        return generated_images

# 사용 예시
if __name__ == "__main__":
    generator = ImageGenerator()
    
    # 스크립트 장면 정의
    script_scenes = [
        {
            "description": "A modern office with a person working on a computer, professional lighting",
            "negative_prompt": "blurry, low quality, distorted",
            "width": 1024,
            "height": 576
        },
        {
            "description": "A person presenting charts and graphs on a screen, business meeting",
            "negative_prompt": "casual, informal, low quality",
            "width": 1024,
            "height": 576
        }
    ]
    
    # 이미지 생성
    images = generator.generate_scene_images(script_scenes)
    print(f"총 {len(images)}개의 이미지가 생성되었습니다.")
```

---

## 영상 생성 AI 툴

### 🎬 상용 AI 영상 생성 도구

#### 1. Runway ML
- **특징**: 텍스트에서 영상 생성
- **장점**: 고품질 영상, 다양한 스타일
- **단점**: 비용이 높음, 생성 시간 오래 걸림
- **가격**: $12-28/월

#### 2. Pika Labs
- **특징**: AI 영상 생성 플랫폼
- **장점**: 빠른 생성 속도, 다양한 옵션
- **단점**: 품질 제한, 길이 제한
- **가격**: 무료 (제한적), $10-20/월

#### 3. Synthesia
- **특징**: AI 아바타 기반 영상 제작
- **장점**: 일관된 아바타, 다국어 지원
- **단점**: 제한적인 커스터마이징
- **가격**: $30-89/월

#### 4. D-ID
- **특징**: AI 아바타와 음성 합성
- **장점**: 자연스러운 아바타 움직임
- **단점**: 아바타 스타일 제한
- **가격**: $5.99-29.99/월

### 🔧 파이썬 코드로 영상 생성

#### OpenCV를 사용한 영상 생성
```python
import cv2
import numpy as np
import os
from PIL import Image
import json

class VideoGenerator:
    def __init__(self, output_dir="output/videos"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def create_video_from_images(self, image_paths, output_path, fps=30, duration_per_image=3):
        """이미지들을 영상으로 변환"""
        if not image_paths:
            raise ValueError("이미지 경로가 비어있습니다.")
        
        # 첫 번째 이미지로 영상 크기 결정
        first_image = cv2.imread(image_paths[0])
        height, width, layers = first_image.shape
        
        # 비디오 라이터 설정
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        for image_path in image_paths:
            if not os.path.exists(image_path):
                print(f"이미지 파일을 찾을 수 없습니다: {image_path}")
                continue
            
            # 이미지 로드
            img = cv2.imread(image_path)
            
            # 이미지 크기 조정
            img = cv2.resize(img, (width, height))
            
            # 지정된 시간 동안 프레임 추가
            for _ in range(fps * duration_per_image):
                out.write(img)
        
        out.release()
        print(f"영상이 생성되었습니다: {output_path}")
    
    def add_transitions(self, video_path, transition_type="fade", duration=1):
        """영상에 전환 효과 추가"""
        # 전환 효과 구현
        pass
    
    def add_text_overlay(self, video_path, text_data):
        """영상에 텍스트 오버레이 추가"""
        cap = cv2.VideoCapture(video_path)
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(video_path.replace('.mp4', '_with_text.mp4'), fourcc, fps, (width, height))
        
        frame_count = 0
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # 텍스트 오버레이 추가
            for text_info in text_data:
                if text_info['start_frame'] <= frame_count <= text_info['end_frame']:
                    cv2.putText(
                        frame, 
                        text_info['text'], 
                        (text_info['x'], text_info['y']), 
                        cv2.FONT_HERSHEY_SIMPLEX, 
                        text_info['font_scale'], 
                        text_info['color'], 
                        text_info['thickness']
                    )
            
            out.write(frame)
            frame_count += 1
        
        cap.release()
        out.release()

# 사용 예시
if __name__ == "__main__":
    generator = VideoGenerator()
    
    # 이미지 경로들
    image_paths = [
        "output/images/scene_001_1.png",
        "output/images/scene_002_1.png",
        "output/images/scene_003_1.png"
    ]
    
    # 영상 생성
    generator.create_video_from_images(
        image_paths=image_paths,
        output_path="output/videos/script_video.mp4",
        fps=30,
        duration_per_image=3
    )
```

#### FFmpeg를 사용한 고급 영상 편집
```python
import ffmpeg
import os

class AdvancedVideoGenerator:
    def __init__(self):
        self.temp_dir = "temp"
        os.makedirs(self.temp_dir, exist_ok=True)
    
    def create_video_with_audio(self, images, audio_file, output_path, fps=30):
        """이미지와 오디오를 결합한 영상 생성"""
        # 이미지들을 영상으로 변환
        video = ffmpeg.input('image_%03d.png', framerate=fps)
        audio = ffmpeg.input(audio_file)
        
        # 영상과 오디오 결합
        out = ffmpeg.output(video, audio, output_path, vcodec='libx264', acodec='aac')
        ffmpeg.run(out, overwrite_output=True)
    
    def add_subtitles(self, video_path, subtitle_file, output_path):
        """자막 추가"""
        video = ffmpeg.input(video_path)
        subtitles = ffmpeg.input(subtitle_file)
        
        out = ffmpeg.output(video, subtitles, output_path, vcodec='libx264')
        ffmpeg.run(out, overwrite_output=True)
    
    def create_slideshow(self, images, output_path, duration_per_slide=3, transition_duration=0.5):
        """슬라이드쇼 영상 생성"""
        # 각 이미지를 지정된 시간 동안 표시
        inputs = []
        for i, image in enumerate(images):
            # 이미지에 지속 시간 설정
            img = ffmpeg.input(image, t=duration_per_slide)
            inputs.append(img)
        
        # 이미지들을 연결
        video = ffmpeg.concat(*inputs, v=1, a=0)
        
        # 출력
        out = ffmpeg.output(video, output_path, vcodec='libx264', pix_fmt='yuv420p')
        ffmpeg.run(out, overwrite_output=True)

# 사용 예시
if __name__ == "__main__":
    generator = AdvancedVideoGenerator()
    
    # 슬라이드쇼 생성
    images = [
        "output/images/scene_001_1.png",
        "output/images/scene_002_1.png",
        "output/images/scene_003_1.png"
    ]
    
    generator.create_slideshow(
        images=images,
        output_path="output/videos/slideshow.mp4",
        duration_per_slide=3,
        transition_duration=0.5
    )
```

---

## 실전 워크플로우

### 📋 스크립트 분석 및 영상 생성 파이프라인

```python
import json
import requests
import os
from datetime import datetime

class ScriptToVideoPipeline:
    def __init__(self, config_file="config.json"):
        self.config = self.load_config(config_file)
        self.image_generator = ImageGenerator()
        self.video_generator = VideoGenerator()
    
    def load_config(self, config_file):
        """설정 파일 로드"""
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def analyze_script(self, script_text):
        """스크립트를 장면별로 분석"""
        # 스크립트를 문단별로 분할
        paragraphs = script_text.split('\n\n')
        
        scenes = []
        for i, paragraph in enumerate(paragraphs):
            if paragraph.strip():
                # 각 문단을 장면으로 분석
                scene = {
                    'scene_id': i + 1,
                    'description': self.extract_scene_description(paragraph),
                    'duration': self.estimate_duration(paragraph),
                    'visual_elements': self.extract_visual_elements(paragraph)
                }
                scenes.append(scene)
        
        return scenes
    
    def extract_scene_description(self, text):
        """장면 설명 추출"""
        # 간단한 키워드 추출 (실제로는 더 정교한 NLP 사용)
        keywords = ['사무실', '회의', '프레젠테이션', '차트', '그래프', '데이터']
        
        for keyword in keywords:
            if keyword in text:
                return f"A professional scene showing {keyword}, business environment, clean and modern"
        
        return "A professional business scene, clean and modern office environment"
    
    def estimate_duration(self, text):
        """텍스트 길이 기반 지속 시간 추정"""
        word_count = len(text.split())
        # 평균 읽기 속도: 분당 200단어
        duration = max(3, word_count / 200 * 60)  # 최소 3초
        return min(duration, 10)  # 최대 10초
    
    def extract_visual_elements(self, text):
        """시각적 요소 추출"""
        elements = []
        if '차트' in text or '그래프' in text:
            elements.append('charts')
        if '데이터' in text:
            elements.append('data_visualization')
        if '회의' in text:
            elements.append('meeting_room')
        return elements
    
    def generate_video_from_script(self, script_text, output_name="generated_video"):
        """스크립트에서 영상 생성"""
        print("1. 스크립트 분석 중...")
        scenes = self.analyze_script(script_text)
        
        print("2. 이미지 생성 중...")
        image_paths = []
        for scene in scenes:
            images = self.image_generator.generate_image(
                prompt=scene['description'],
                width=1920,
                height=1080
            )
            
            # 이미지 저장
            for j, img in enumerate(images):
                filename = f"scene_{scene['scene_id']:03d}_{j+1}.png"
                img_path = f"output/images/{filename}"
                os.makedirs(os.path.dirname(img_path), exist_ok=True)
                img.save(img_path)
                image_paths.append(img_path)
        
        print("3. 영상 생성 중...")
        output_path = f"output/videos/{output_name}.mp4"
        self.video_generator.create_video_from_images(
            image_paths=image_paths,
            output_path=output_path,
            fps=30
        )
        
        print(f"영상 생성 완료: {output_path}")
        return output_path

# 사용 예시
if __name__ == "__main__":
    pipeline = ScriptToVideoPipeline()
    
    # 스크립트 예시
    script = """
    오늘은 데이터 분석의 중요성에 대해 이야기해보겠습니다.
    
    먼저 차트를 통해 매출 증가 추이를 확인해보겠습니다.
    
    이 데이터를 바탕으로 향후 전략을 수립해야 합니다.
    """
    
    # 영상 생성
    video_path = pipeline.generate_video_from_script(script, "data_analysis_video")
    print(f"생성된 영상: {video_path}")
```

---

## 고급 기법

### 🎯 실시간 영상 생성

```python
import cv2
import numpy as np
import threading
import time

class RealTimeVideoGenerator:
    def __init__(self):
        self.is_running = False
        self.current_frame = None
    
    def apply_ai_filter(self, frame):
        """AI 필터 적용"""
        # 간단한 필터 예시 (실제로는 AI 모델 사용)
        filtered = cv2.GaussianBlur(frame, (15, 15), 0)
        return filtered
    
    def generate_real_time_video(self):
        """실시간 영상 생성"""
        cap = cv2.VideoCapture(0)  # 웹캠 사용
        
        while self.is_running:
            ret, frame = cap.read()
            if not ret:
                break
            
            # AI 필터 적용
            processed_frame = self.apply_ai_filter(frame)
            
            # 화면에 표시
            cv2.imshow('Real-time Generated Video', processed_frame)
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        cap.release()
        cv2.destroyAllWindows()
    
    def start(self):
        """실시간 영상 생성 시작"""
        self.is_running = True
        thread = threading.Thread(target=self.generate_real_time_video)
        thread.start()
        return thread
    
    def stop(self):
        """실시간 영상 생성 중지"""
        self.is_running = False

# 사용 예시
if __name__ == "__main__":
    generator = RealTimeVideoGenerator()
    thread = generator.start()
    
    try:
        while True:
            time.sleep(0.1)
    except KeyboardInterrupt:
        generator.stop()
        thread.join()
```

### 🎨 스타일 일관성 유지

```python
class StyleConsistentGenerator:
    def __init__(self, style_reference_image):
        self.style_reference = style_reference_image
        self.style_embeddings = self.extract_style_embeddings()
    
    def extract_style_embeddings(self):
        """스타일 참조 이미지에서 스타일 임베딩 추출"""
        # 실제로는 VGG나 다른 모델을 사용하여 스타일 추출
        pass
    
    def generate_consistent_images(self, prompts):
        """일관된 스타일의 이미지들 생성"""
        consistent_images = []
        
        for prompt in prompts:
            # 스타일 일관성을 위한 프롬프트 수정
            style_prompt = f"{prompt}, in the style of {self.style_reference}"
            
            # 이미지 생성
            image = self.image_generator.generate_image(style_prompt)
            consistent_images.append(image)
        
        return consistent_images
```

---

## 비용 최적화 전략

### 💰 비용 효율적인 접근법

#### 1. 하이브리드 접근법
```python
class CostOptimizedGenerator:
    def __init__(self):
        self.free_tools = ['stable-diffusion', 'local-models']
        self.paid_tools = ['dall-e', 'midjourney']
        self.budget_limit = 100  # 월 예산
    
    def choose_generation_method(self, complexity, quality_requirement):
        """복잡도와 품질 요구사항에 따른 방법 선택"""
        if complexity == 'low' and quality_requirement == 'medium':
            return 'stable-diffusion'  # 무료
        elif complexity == 'high' and quality_requirement == 'high':
            return 'dall-e'  # 유료
        else:
            return 'stable-diffusion'  # 기본값
```

#### 2. 배치 처리 최적화
```python
def batch_generate_images(prompts, batch_size=5):
    """배치 단위로 이미지 생성하여 비용 절약"""
    batches = [prompts[i:i+batch_size] for i in range(0, len(prompts), batch_size)]
    
    all_images = []
    for batch in batches:
        # 배치 단위로 API 호출
        images = generate_images_batch(batch)
        all_images.extend(images)
    
    return all_images
```

#### 3. 캐싱 시스템
```python
import hashlib
import json

class ImageCache:
    def __init__(self, cache_dir="cache"):
        self.cache_dir = cache_dir
        os.makedirs(cache_dir, exist_ok=True)
    
    def get_cache_key(self, prompt, style, size):
        """캐시 키 생성"""
        content = f"{prompt}_{style}_{size}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def get_cached_image(self, prompt, style, size):
        """캐시된 이미지 가져오기"""
        cache_key = self.get_cache_key(prompt, style, size)
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.png")
        
        if os.path.exists(cache_path):
            return Image.open(cache_path)
        return None
    
    def cache_image(self, image, prompt, style, size):
        """이미지 캐시에 저장"""
        cache_key = self.get_cache_key(prompt, style, size)
        cache_path = os.path.join(self.cache_dir, f"{cache_key}.png")
        image.save(cache_path)
```

---

## 📊 성능 모니터링

```python
import time
import psutil
import json
from datetime import datetime

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {
            'generation_times': [],
            'memory_usage': [],
            'cpu_usage': [],
            'success_rate': 0
        }
    
    def start_monitoring(self):
        """성능 모니터링 시작"""
        self.start_time = time.time()
        self.start_memory = psutil.virtual_memory().used
        self.start_cpu = psutil.cpu_percent()
    
    def end_monitoring(self, success=True):
        """성능 모니터링 종료"""
        end_time = time.time()
        generation_time = end_time - self.start_time
        
        self.metrics['generation_times'].append(generation_time)
        self.metrics['memory_usage'].append(psutil.virtual_memory().used - self.start_memory)
        self.metrics['cpu_usage'].append(psutil.cpu_percent() - self.start_cpu)
        
        if success:
            self.metrics['success_rate'] += 1
    
    def get_report(self):
        """성능 리포트 생성"""
        if not self.metrics['generation_times']:
            return "아직 데이터가 없습니다."
        
        avg_time = sum(self.metrics['generation_times']) / len(self.metrics['generation_times'])
        avg_memory = sum(self.metrics['memory_usage']) / len(self.metrics['memory_usage'])
        avg_cpu = sum(self.metrics['cpu_usage']) / len(self.metrics['cpu_usage'])
        
        report = {
            'average_generation_time': avg_time,
            'average_memory_usage': avg_memory,
            'average_cpu_usage': avg_cpu,
            'total_generations': len(self.metrics['generation_times']),
            'success_rate': self.metrics['success_rate'] / len(self.metrics['generation_times']) * 100
        }
        
        return report
```

---

## 🚀 실행 가이드

### 1. 환경 설정
```bash
# 필요한 라이브러리 설치
pip install diffusers transformers torch opencv-python pillow ffmpeg-python psutil

# GPU 사용을 위한 CUDA 설치 (선택사항)
# CUDA 11.8 또는 12.1 설치 후 PyTorch 재설치
```

### 2. 설정 파일 생성
```json
{
    "api_keys": {
        "openai": "your_openai_api_key",
        "huggingface": "your_huggingface_token"
    },
    "output_settings": {
        "image_width": 1920,
        "image_height": 1080,
        "video_fps": 30,
        "duration_per_scene": 3
    },
    "quality_settings": {
        "image_quality": "high",
        "video_quality": "high"
    }
}
```

### 3. 실행
```python
# 기본 실행
python script_to_video.py

# 설정 파일 지정
python script_to_video.py --config custom_config.json

# 배치 처리
python batch_generate.py --input scripts/ --output videos/
```

---

## 📝 결론

이 가이드를 통해 스크립트 기반으로 이미지와 영상을 자동 생성할 수 있습니다. 

**주요 장점:**
- 완전 자동화된 콘텐츠 제작
- 일관된 품질의 결과물
- 시간과 비용 절약
- 확장 가능한 시스템

**주의사항:**
- AI 모델의 한계 이해
- 저작권 및 윤리적 고려사항
- 품질 검증 필요
- 비용 관리 중요

이 도구들을 활용하여 효율적인 콘텐츠 제작 파이프라인을 구축하시기 바랍니다.

